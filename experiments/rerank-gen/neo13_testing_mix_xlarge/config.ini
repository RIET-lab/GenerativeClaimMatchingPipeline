[training]
epochs = 1
lr = 2e-5
max_length = 256
per_chip_batch_size = 1
save_dir = training
eval_steps = 25
print_steps = 5
mask_prior = false
optimization = mixed
lr_schedule = constant
candidate_selection = experiments/candidate_selection/finetune_st5_xlarge_claims_negs

[eval]
candidate_selection = experiments/candidate_selection/finetune_st5_xlarge_claims_negs
n_candidates = 5

[model]
model_string = EleutherAI/gpt-neo-1.3B
