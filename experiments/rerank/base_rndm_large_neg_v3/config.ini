[training]
lr = 2e-5
batch_size = 8
adapters_only = False
max_length = 192
epochs = 1
candidate_selection_experiment = ./experiments/candidate_selection/finetune_st5_large_claims_negs
adapter_epochs = 20
adapter_lr = 1e-4
pretrained = False

[model]
model_string = roberta-base
version = 3